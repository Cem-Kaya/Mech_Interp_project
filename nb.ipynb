{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Visible User Prompt =====\n",
      "What is the capital of Turkey?\n",
      "\n",
      "===== Combined Prompt (Internal) =====\n",
      "<｜begin▁of▁sentence｜><｜User｜>What is the capital of Turkey?<｜Assistant｜><think>\n",
      "\n",
      "\n",
      "===== Input Token Mapping (Combined) =====\n",
      "{151646: '<｜begin▁of▁sentence｜>', 151644: '<｜User｜>', 3838: 'What', 374: ' is', 279: ' the', 6722: ' capital', 315: ' of', 17009: ' Turkey', 30: '?', 151645: '<｜Assistant｜>', 151648: '<think>', 198: '\\n'}\n",
      "\n",
      "===== Generated Token Mapping =====\n",
      "{151646: '<｜begin▁of▁sentence｜>', 151644: '<｜User｜>', 3838: 'What', 374: ' is', 279: ' the', 6722: ' capital', 315: ' of', 17009: ' Turkey', 30: '?', 151645: '<｜Assistant｜>', 151648: '<think>', 198: '\\n', 32313: 'Okay', 11: ',', 773: ' so', 358: ' I', 1184: ' need', 311: ' to', 7071: ' figure', 700: ' out', 13: '.', 2776: \"'m\", 537: ' not', 6896: ' exactly', 2704: ' sure', 714: ' but', 1744: ' think', 92999: ' capitals', 525: ' are', 5990: ' usually', 1887: ' main', 9720: ' cities', 1251: ' people', 728: ' go', 369: ' for', 2562: ' business', 476: ' or', 4357: ' events', 6099: ' remember', 429: ' that', 304: ' in', 807: ' they', 614: ' have', 1075: ' like', 53368: ' Istanbul', 323: ' and', 1549: ' again', 13824: ' Wait', 432: ' it', 1852: ' same', 1992: ' place', 10696: ' Maybe', 594: \"'s\", 2598: ' called', 3003: \"'ve\", 6617: ' heard', 1573: ' before', 1988: ' But', 220: ' ', 16: '1', 15: '0', 4: '%', 3654: ' certain', 6771: ' Let', 752: ' me', 1414: ' know', 1429: ' most', 11245: ' famous', 3283: ' city', 4658: ' probably', 4710: ' \\n\\n', 40: 'I', 1265: ' should', 1990: ' double', 15934: '-check', 646: ' can', 911: ' about', 6789: ' layout', 264: ' a', 3146: ' country', 8865: ' spread', 18202: ' covering', 2696: ' lot', 4268: ' land', 2619: ' There', 10200: ' north', 10984: ' east', 9806: ' south', 576: ' The', 9966: ' supposed', 387: ' be', 8622: ' central', 18719: ' hub', 7772: ' largest', 3643: ' makes', 5530: ' sense', 34359: ' populated', 3170: ' why', 382: '.\\n\\n', 1083: ' also', 3545: ' often', 330: ' \"', 12730: 'City', 6326: ' East', 1: '\"', 1576: ' because', 1181: ' its', 3728: ' location', 23149: ' eastern', 949: ' part', 2938: ' That', 1661: ' good', 86801: ' mnemonic', 2055: ' So', 10687: ' putting', 678: ' all', 3786: ' together', 1513: ' don', 944: \"'t\", 1052: ' there', 894: ' any', 1008: ' other', 803: ' more', 5089: ' significant', 1091: ' than', 1084: ' It', 3460: ' large', 2989: ' important', 825: ' one', 14190: 'Wait', 7025: ' sometimes', 1045: ' some', 37597: ' contexts', 2874: ' reason', 22707: ' administrative', 4126: ' center', 94451: ' populous', 6955: ' economic', 4746: ' heart', 9834: ' yes', 3270: ' write', 1495: ' down', 624: '.\\n', 151649: '</think>', 271: '\\n\\n', 785: 'The', 3259: ' making', 4948: ' political', 151643: '<｜end▁of▁sentence｜>'}\n",
      "\n",
      "===== Final Decoded Output (with special tokens) =====\n",
      "<｜begin▁of▁sentence｜><｜begin▁of▁sentence｜><｜User｜>What is the capital of Turkey?<｜Assistant｜><think>\n",
      "Okay, so I need to figure out the capital of Turkey. I'm not exactly sure, but I think capitals are usually the main cities people go to for business or events. I remember that in Turkey, they have cities like Istanbul, Istanbul, and Istanbul again. Wait, is it the same place? Maybe it's called Istanbul? I think I've heard that before. But I'm not 100% certain. Let me think. I know Istanbul is the most famous city in Turkey, so it's probably the capital. \n",
      "\n",
      "I should double-check. Maybe I can think about the layout of Turkey. Turkey is a country that's spread out, covering a lot of land. There are cities in the north, the east, and the south. The capital is supposed to be the central business hub. I think Istanbul is the largest city, so that makes sense. I've heard that Istanbul is the most populated city, so that's probably why it's the capital.\n",
      "\n",
      "I also remember that the capital is often called the \"City of the East\" because of its location in the eastern part of Turkey. That's a good mnemonic. So, putting it all together, the capital is Istanbul. I don't think there's any other city that's more significant than Istanbul. It's not a large city, but it's the most important one in Turkey.\n",
      "\n",
      "Wait, is there any other city that's sometimes called the capital? Maybe in some contexts, but I don't think so. I think the main reason it's the capital is because it's the administrative center, the most populous city, and it's the economic heart of the country. So, yes, Istanbul is the capital. I should probably write that down.\n",
      "</think>\n",
      "\n",
      "The capital of Turkey is Istanbul. It is the most populous city and the administrative center of the country, making it the economic and political hub.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 1) Load model and tokenizer\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Remove \"device_map='auto'\" and move the model to the GPU explicitly\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")  # <--- Move model to GPU\n",
    "\n",
    "# 2) The user's visible question\n",
    "user_text = \"What is the capital of Turkey?\"\n",
    "\n",
    "# 3) Build the combined prompt\n",
    "combined_prompt = (\n",
    "    \"<｜begin▁of▁sentence｜>\"\n",
    "    + \"<｜User｜>\"\n",
    "    + user_text\n",
    "    + \"<｜Assistant｜>\"\n",
    "    + \"<think>\\n\"\n",
    ")\n",
    "\n",
    "# 4) Tokenize combined prompt\n",
    "encoded = tokenizer(combined_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Move tokenized input to GPU\n",
    "input_ids = encoded.input_ids.to(\"cuda\")\n",
    "attention_mask = encoded.attention_mask.to(\"cuda\")\n",
    "\n",
    "# 5) Create a dictionary mapping input token IDs -> token text\n",
    "input_ids_list = input_ids[0].tolist()\n",
    "input_token_map = {\n",
    "    tid: tokenizer.decode([tid], skip_special_tokens=False)\n",
    "    for tid in input_ids_list\n",
    "}\n",
    "\n",
    "print(\"===== Visible User Prompt =====\")\n",
    "print(user_text)\n",
    "\n",
    "print(\"\\n===== Combined Prompt (Internal) =====\")\n",
    "print(combined_prompt)\n",
    "\n",
    "print(\"\\n===== Input Token Mapping (Combined) =====\")\n",
    "print(input_token_map)\n",
    "\n",
    "# 6) Generate output using GPU\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=1024,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "# 7) Map generated token IDs -> token text\n",
    "generated_ids_list = output_ids[0].tolist()\n",
    "generated_token_map = {\n",
    "    tid: tokenizer.decode([tid], skip_special_tokens=False)\n",
    "    for tid in generated_ids_list\n",
    "}\n",
    "\n",
    "print(\"\\n===== Generated Token Mapping =====\")\n",
    "print(generated_token_map)\n",
    "\n",
    "# 8) Decode final output (keep special tokens visible)\n",
    "generated_text = tokenizer.decode(\n",
    "    generated_ids_list,\n",
    "    skip_special_tokens=False\n",
    ")\n",
    "\n",
    "print(\"\\n===== Final Decoded Output (with special tokens) =====\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
